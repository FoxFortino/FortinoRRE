
     active environment : /lustre/lrspec/users/2649/anaconda3/envs/fox
    active env location : /lustre/lrspec/users/2649/anaconda3/envs/fox
            shell level : 1
       user config file : /home/2649/.condarc
 populated config files : /home/2649/.condarc
          conda version : 4.5.11
    conda-build version : 3.15.1
         python version : 3.7.0.final.0
       base environment : /opt/shared/anaconda/5.3.1-python3  (read only)
           channel URLs : https://repo.anaconda.com/pkgs/main/linux-64
                          https://repo.anaconda.com/pkgs/main/noarch
                          https://repo.anaconda.com/pkgs/free/linux-64
                          https://repo.anaconda.com/pkgs/free/noarch
                          https://repo.anaconda.com/pkgs/r/linux-64
                          https://repo.anaconda.com/pkgs/r/noarch
                          https://repo.anaconda.com/pkgs/pro/linux-64
                          https://repo.anaconda.com/pkgs/pro/noarch
                          https://conda.anaconda.org/conda-forge/linux-64
                          https://conda.anaconda.org/conda-forge/noarch
          package cache : /opt/shared/anaconda/5.3.1-python3/pkgs
                          /home/2649/.conda/pkgs
       envs directories : /home/2649/.conda/envs
                          /opt/shared/anaconda/5.3.1-python3/envs
               platform : linux-64
             user-agent : conda/4.5.11 requests/2.19.1 CPython/3.7.0 Linux/3.10.0-1127.19.1.el7.x86_64 centos/7 glibc/2.17
                UID:GID : 2649:1209
             netrc file : None
           offline mode : False

WARNING:tensorflow:From /lustre/lrspec/users/2649/anaconda3/envs/fox/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
Archive:  /lustre/lrspec/users/2649/models/FortinoRRE/80/training_set.zip
 extracting: /lustre/lrspec/users/2649/models/FortinoRRE/80/training_set/trainImages.npy.gz  
 extracting: /lustre/lrspec/users/2649/models/FortinoRRE/80/training_set/trainLabels.npy.gz  
 extracting: /lustre/lrspec/users/2649/models/FortinoRRE/80/training_set/testImages.npy.gz  
 extracting: /lustre/lrspec/users/2649/models/FortinoRRE/80/training_set/testLabels.npy.gz  
 extracting: /lustre/lrspec/users/2649/models/FortinoRRE/80/training_set/testTypeNames.npy.gz  
 extracting: /lustre/lrspec/users/2649/models/FortinoRRE/80/training_set/typeNamesList.npy.gz  
 extracting: /lustre/lrspec/users/2649/models/FortinoRRE/80/training_set/trainFilenames.npy.gz  
 extracting: /lustre/lrspec/users/2649/models/FortinoRRE/80/training_set/trainTypeNames.npy.gz  
WARNING:tensorflow:From /lustre/lrspec/users/2649/anaconda3/envs/fox/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2022-11-05 19:30:54.606197: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/shared/slurm/lib:/lustre/lrspec/users/2649/anaconda3/envs/fox/lib/:/lustre/lrspec/users/2649/anaconda3/envs/fox/lib/
2022-11-05 19:30:54.607211: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-11-05 19:30:54.607248: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (r1n18): /proc/driver/nvidia/version does not exist
2022-11-05 19:30:54.612316: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-11-05 19:30:54.790920: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
Warning: You will need to install 'PyQt5' if you want to use the graphical interface. Using the automatic library will continue to work.
Warning: You will need to install 'PyQt5' if you want to use the graphical interface. Using the automatic library will continue to work.
Generating oversampled arrays...
Before OverSample
[    0.   160.  1920.  8000. 12160. 17200. 15280. 13040.  8800.  7680.
  5680.  5360.  5520.  4080.  2640.  2640.  1920.  1040.     0.     0.
  1040.  2560.  2560.  2080.  1280.  1280.   800.  1440.  1680.  1200.
   720.   560.   640.   240.   560.   640.     0.     0.     0.   800.
  1680.  1440.  2000.  1040.  1440.  1280.  1040.   560.   560.   640.
     0.   160.   400.   160.     0.     0.     0.     0.     0.     0.
    80.    80.     0.     0.     0.     0.     0.    80.     0.     0.
    80.     0.     0.     0.     0.   640.   880.   240.    80.     0.
   240.   320.   240.   480.   160.     0.    80.   160.    80.     0.
     0.     0.   400.   400.   320.   400.   640.  1120.   480.   480.
   160.   400.   240.   480.   320.   320.    80.    80.    80.   240.
   560.  1200.  1200.  1520.   720.   880.  1280.   560.   800.   320.
   400.   400.   400.   400.   160.   240.     0.     0.     0.     0.
     0.     0.   160.   240.     0.     0.    80.    80.    80.    80.
     0.     0.     0.     0.   480.   800.  1040.  1680.  1040.   960.
   880.   720.   640.   720.   560.   480.   320.   240.    80.   320.
   160.    80.     0.     0.     0.     0.     0.     0.     0.     0.
     0.   400.     0.     0.     0.     0.     0.     0.     0.     0.
     0.   320.    80.   800.   960.   720.   720.   560.   560.   880.
   400.   480.   400.   720.   240.   400.   480.   320.     0.     0.
   480.  1280.  1680.  2000.  1200.  1440.   560.   880.  1040.   640.
   560.   240.   240.   160.   240.   720.     0.     0.     0.     0.
   240.   480.   320.     0.    80.     0.   320.   240.     0.   160.
     0.     0.     0.   160.     0.     0.     0.    80.   240.   320.
    80.   240.   160.    80.   160.   480.   160.    80.   240.   160.
    80.    80.     0.     0.     0.     0.     0.     0.     0.    80.
   160.     0.     0.     0.     0.     0.     0.     0.    80.     0.
     0.     0.     0.     0.     0.     0.     0.    80.     0.     0.
     0.     0.     0.    80.     0.     0.    80.     0.     0.     0.
     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
     0.     0.     0.     0.     0.     0.]
[    0. 17280. 17280. 16000. 12160. 17200. 15280. 13040. 17600. 15360.
 17040. 16080. 16560. 16320. 18480. 18480. 17280. 17680.     0.     0.
 17680. 17920. 17920. 16640. 16640. 16640. 17600. 17280. 16800. 16800.
 17280. 17360. 17280. 17280. 17360. 17280.     0.     0.     0. 17600.
 16800. 17280. 18000. 17680. 17280. 16640. 17680. 17360. 17360. 17280.
     0. 17280. 17200. 17280.     0.     0.     0.     0.     0.     0.
 17200. 17200.     0.     0.     0.     0.     0. 17200.     0.     0.
 17200.     0.     0.     0.     0. 17280. 17600. 17280. 17200.     0.
 17280. 17280. 17280. 17280. 17280.     0. 17200. 17280. 17200.     0.
     0.     0. 17200. 17200. 17280. 17200. 17280. 16800. 17280. 17280.
 17280. 17200. 17280. 17280. 17280. 17280. 17200. 17200. 17200. 17280.
 17360. 16800. 16800. 16720. 17280. 17600. 16640. 17360. 17600. 17280.
 17200. 17200. 17200. 17200. 17280. 17280.     0.     0.     0.     0.
     0.     0. 17280. 17280.     0.     0. 17200. 17200. 17200. 17200.
     0.     0.     0.     0. 17280. 17600. 17680. 16800. 17680. 17280.
 17600. 17280. 17280. 17280. 17360. 17280. 17280. 17280. 17200. 17280.
 17280. 17200.     0.     0.     0.     0.     0.     0.     0.     0.
     0. 17200.     0.     0.     0.     0.     0.     0.     0.     0.
     0. 17280. 17200. 17600. 17280. 17280. 17280. 17360. 17360. 17600.
 17200. 17280. 17200. 17280. 17280. 17200. 17280. 17280.     0.     0.
 17280. 16640. 16800. 18000. 16800. 17280. 17360. 17600. 17680. 17280.
 17360. 17280. 17280. 17280. 17280. 17280.     0.     0.     0.     0.
 17280. 17280. 17280.     0. 17200.     0. 17280. 17280.     0. 17280.
     0.     0.     0. 17280.     0.     0.     0. 17200. 17280. 17280.
 17200. 17280. 17280. 17200. 17280. 17280. 17280. 17200. 17280. 17280.
 17200. 17200.     0.     0.     0.     0.     0.     0.     0. 17200.
 17280.     0.     0.     0.     0.     0.     0.     0. 17200.     0.
     0.     0.     0.     0.     0.     0.     0. 17200.     0.     0.
     0.     0.     0. 17200.     0.     0. 17200.     0.     0.     0.
     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
     0.     0.     0.     0.     0.     0.]
[  0 108   9   2   1   1   1   1   2   2   3   3   3   4   7   7   9  17
   0   0  17   7   7   8  13  13  22  12  10  14  24  31  27  72  31  27
   0   0   0  22  10  12   9  17  12  13  17  31  31  27   0 108  43 108
   0   0   0   0   0   0 215 215   0   0   0   0   0 215   0   0 215   0
   0   0   0  27  20  72 215   0  72  54  72  36 108   0 215 108 215   0
   0   0  43  43  54  43  27  15  36  36 108  43  72  36  54  54 215 215
 215  72  31  14  14  11  24  20  13  31  22  54  43  43  43  43 108  72
   0   0   0   0   0   0 108  72   0   0 215 215 215 215   0   0   0   0
  36  22  17  10  17  18  20  24  27  24  31  36  54  72 215  54 108 215
   0   0   0   0   0   0   0   0   0  43   0   0   0   0   0   0   0   0
   0  54 215  22  18  24  24  31  31  20  43  36  43  24  72  43  36  54
   0   0  36  13  10   9  14  12  31  20  17  27  31  72  72 108  72  24
   0   0   0   0  72  36  54   0 215   0  54  72   0 108   0   0   0 108
   0   0   0 215  72  54 215  72 108 215 108  36 108 215  72 108 215 215
   0   0   0   0   0   0   0 215 108   0   0   0   0   0   0   0 215   0
   0   0   0   0   0   0   0 215   0   0   0   0   0 215   0   0 215   0
   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
3162000 207120
Shuffling...
images shuffling...
207120
labels shuffling...
207120
207120
Before Shuffling
Shuffling...
images shuffling...
3162000
labels shuffling...
3162000
After Shuffling
Saving oversampled arrays...
Saving complete.
No improvement in Subtype macroF1 score in 1000 epochs.
Ending training.
Model saved to: /lustre/lrspec/users/2649/models/FortinoRRE/80/tensorflow_model.ckpt
